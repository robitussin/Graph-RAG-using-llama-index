{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Graph Extraction using PropertyGraphIndex\n",
    "Source data: faculty manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"facultymanual.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"abc12345\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 148/148 [00:00<00:00, 2023.91it/s]\n",
      "Extracting paths from text with schema:  39%|███▊      | 58/150 [01:38<02:01,  1.32s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9028776551298324 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29768, Requested 808. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2043250424960491 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29945, Requested 732. Please try again in 1.354s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  41%|████      | 61/150 [01:47<03:08,  2.12s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15281328652711879 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29508, Requested 750. Please try again in 516ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  46%|████▌     | 69/150 [02:03<01:55,  1.43s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7119904917892269 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29644, Requested 831. Please try again in 950ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  57%|█████▋    | 86/150 [02:40<01:48,  1.69s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9740431177385039 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29413, Requested 787. Please try again in 400ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  65%|██████▍   | 97/150 [02:59<01:02,  1.19s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08863289752644288 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29721, Requested 755. Please try again in 952ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  69%|██████▉   | 104/150 [03:15<01:25,  1.86s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9060156749403036 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29381, Requested 1092. Please try again in 945ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema:  93%|█████████▎| 139/150 [04:28<00:23,  2.17s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3512539410426644 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-BGsG5y0p7qAnSh6f8nhzI5kJ on tokens per min (TPM): Limit 30000, Used 29663, Requested 849. Please try again in 1.024s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Extracting paths from text with schema: 100%|██████████| 150/150 [04:49<00:00,  1.93s/it]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    kg_extractors=[\n",
    "        SchemaLLMPathExtractor(\n",
    "            llm=OpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "        )\n",
    "    ],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University -> PART_OF -> International Association of Universities\n",
      "University -> PART_OF -> Association of Southeast Asia Higher Institutions of Learning\n",
      "University -> PART_OF -> Philippine Association of Colleges and Universities\n",
      "University -> PART_OF -> University Athletic Association of the Philippines\n",
      "Philippine Law School -> PART_OF -> NATIONAL UNIVERSITY\n",
      "National Academy -> PART_OF -> NATIONAL UNIVERSITY\n",
      "Colegio Mercantil -> PART_OF -> NATIONAL UNIVERSITY\n",
      "NATIONAL UNIVERSITY -> LOCATED_IN -> Quiapo, City of Manila\n",
      "National University -> LOCATED_IN -> customer premises\n",
      "National University -> LOCATED_IN -> campus\n",
      "HR -> PART_OF -> National University\n",
      "National University -> LOCATED_IN -> National University campus\n",
      "National University -> PART_OF -> Human Resources\n",
      "National University -> PART_OF -> Human Resources Division\n",
      "National University -> LOCATED_IN -> community\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    include_text=False,  # include source text in returned nodes, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Who is the founder of National University?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don Mariano Fortunato Jhocson is the founder of National University.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(include_text=True)\n",
    "\n",
    "response = query_engine.query(\"Who is the founder of National University?\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the graph already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store,\n",
    "    llm=OpenAI(model=\"gpt-4o\", temperature=0.3),\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faculty Services Office -> PART_OF -> FSO\n",
      "Campus HRO -> PART_OF -> academic and employment credentials\n",
      "NIKKA E. CELESTE -> WORKED_ON -> Talent Development\n",
      "Academic Operations Division -> PART_OF -> Academic Operations\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    include_text=False,  # include source text in returned nodes, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"What is the maximum OTE score\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A faculty member can change their status from part-time to full-time by taking on a full-time teaching load per term. The steps involved in this transition typically include accepting a workload of twenty-four (24) credit hours per term and committing to a forty (40) hour work week.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(include_text=True)\n",
    "\n",
    "response = query_engine.query(\"?\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core import Document\n",
    "\n",
    "# document = Document(text=\"What are the four SPES components?\")\n",
    "\n",
    "# index.insert(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nodes = index.as_retriever(include_text=False).retrieve(\"LlamaIndex\")\n",
    "\n",
    "# print(nodes[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
